---
title: "Misclassification Activity for JSM 2024 Short Course"
author: "set below"
date: "set below"
output: 
  beamer_presentation:
    theme: "Boadilla"
    colortheme: "orchid"
header-includes:
  - \AtBeginDocument{\title[]{Misclassification Activity\\JSM 2024 Short Course}}
  - \AtBeginDocument{\author[]{Paul Gustafson}}
  - \AtBeginDocument{\date[]{August 3, 2024}}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=F}
### global reproducibility
set.seed(1234)
### sane output
options(digits=3)
options(width=65)
```

## Recall this example 

```{r}
data.tbl <- matrix(c(45,94,257,945),
  dimnames = list(c("CHD+", "CHD-"),c("Resin+", "Resin-")),
  nrow = 2, byrow = TRUE)
```

```{r}
data.tbl
```
## Naive analysis presuming correct exposure classification

Inference for exposure-disease odds-ratio

```{r}
logOR.hat <- sum(c(1,-1,-1,1)*log(as.vector(data.tbl)))

logOR.SE <- sqrt(sum(1/as.vector(data.tbl)))

exp(logOR.hat + c(0, -1.96, 1.96)*logOR.SE)
```

## Assuming nondifferential exposure misclassification with 90% sensitivity and 80% specificity

Again, recall from slides:

```{r, message=F, warning=F}
require(episensr)

ft <- misclassification(data.tbl,
 type="exposure", bias_parms=c(0.9, 0.9, 0.8, 0.8))

# point and interval estimation of OR
ft$adj.measures[2,]
```


## Activity A 

Check you can reproduce one of the **differential** classification adjustments given in the slides (i.e., one of the off-diagonal table entries on slide 151).

For instance, try presuming 90% specificity for all subjects, but sensitivity of 90% for controls, compared to 80% for cases.

Might help:

```{r,eval=F}
help(misclassification)
```



## Activity B: Uncertainty about misclassification rates 

Say the investigator is confident that the misclassification is nondifferential.    

Has 85% sensitivity and 85% specificity as "best guesses."  

But thinks either guess could be off by as much as five percentage points.

Can you look at
```{r, eval=F}
help(probsens)
```
and then provide an appropriate analysis?

HINT: First example in the help gives a template.

HINT: For simplicity, maybe "triangular" or "uniform" instead of "trapezoidal"



## Activity C - Role of data

We have useful heuristics in statistics, such as the primal role of $\sqrt{n}$.    

If I want interval estimates *twice* as narrow, I likely need about *four times* as much data.

Repeat Activity B, but with four times as much data.   (Simplest to just keep cell *proportions* fixed in the 2 by 2 data table).

Reflect on what you find.



## Activity D - Bayesian approach

Factor the joint dist. of $(X,X^*,Y)$ in terms of $(Y)$, $(X|Y)$, $(X^*|X,Y)$.

Leave $(Y)$ as unmodeled [since $Y$ observed, and given case-control design, parameter of most interest is determined by $X|Y$)].

Parameterize as $Pr(X=1|Y=y)=r_y$, and
\begin{align*}
Pr(X^*=X|X=x, Y=y)   &=
\left\{
\begin{array}{cc}
Sp & \mbox{if\; } x=0, \\
Sn & \mbox{if\; } x=1. \\
\end{array}
\right.
\end{align*}

Parameter of most interest: $\psi = \log OR(X,Y) = \mbox{logit}(r_1) - \mbox{logit}(r_0)$.

Priors $r_{j} \sim \mbox{Unif}(0,1)$, $Sn \sim \mbox{beta}(a_{sn},b_{sn})$,$Sp \sim \mbox{beta}(a_{sp},b_{sp})$.


## Activity D, continued

A bit too much overhead with trying to get JAGS/rJAGS going in a matter of minutes (unless you have experience...)

Here (meaning sitting in the .Rmd file generating these slides) is a bespoke R function (called **bespoke()**)
to do MCMC for this model/prior only:


```{r, echo=F, message=F}
require("rje")
```


```{r, echo=F}
bespoke <- function(n.0, n.1, mstr.0, mstr.1, a.sn, b.sn, a.sp, b.sp, 
                    N.REP=50000, N.BURN=100) {

  ### INPUTS
  ### n.j is size of control (j=0) and case (j=1) samples
  ### mstr.j is number (out of n.j) of apparently exposed
  ### a.sn, b.sn, a.sp, b.sp are hyperparameters
  
  ### LATENTS
  ### m.j is number (out of n.j) actually exposed
  ### t.j is number (out of mstr.j) actually exposed amongst the apparents

  ### OUTPUT output will be matrix, MC sample from posterior 
  ans <- matrix(NA, N.REP, 8)
  colnames(ans) <- c("r0","r1","sn","sp","m0","m1","t0","t1")
  
  ### arbitrary initialization of latent data
  t.0 <- round(mstr.0/3); m.0 <- round(1.2*t.0)
  t.1 <- round(mstr.1/3); m.1 <- round(1.2*t.0)

  ### output will be matrix, MC sample from posterior, parameters 
  ans <- matrix(NA, N.REP, 8)
  colnames(ans) <- c("r0","r1","sn","sp","m0","m1","t0","t1")
  
  for (i in (-N.BURN):N.REP) {

    ### update parameters given latent data
    r.0 <- rbeta(1, 1+m.0, 1+n.0-m.0)
    r.1 <- rbeta(1, 1+m.1, 1+n.1-m.1)
    
    sn <- rbeta(1, a.sn + t.0 + t.1, b.sn + (m.0-t.0) + (m.1-t.1))
    sp <- rbeta(1, a.sp + (n.0-mstr.0)-(m.0-t.0) + (n.1-mstr.1)-(m.1-t.1),
               b.sp + (mstr.0-t.0) + (mstr.1-t.1))

    ### update latent data given parameters

    ### control group
    ### true positives amongst apparent positives
    t.0 <- rbinom(1, size=mstr.0,     prob=r.0*sn/(r.0*sn + (1-r.0)*(1-sp))) 
    ### add in true positives amongst apparent negatives               
    m.0 <- t.0 + rbinom(1, size=n.0-mstr.0, prob=r.0*(1-sn)/(r.0*(1-sn) + (1-r.0)*sp))  

    ### case group
    ### true positives amongst apparent positives
    t.1 <- rbinom(1, size=mstr.1,     prob=r.1*sn/(r.1*sn + (1-r.1)*(1-sp))) 
    ### add in true positives amongst apparent negatives               
    m.1 <- t.1 + rbinom(1, size=n.1-mstr.1, prob=r.1*(1-sn)/(r.1*(1-sn) + (1-r.1)*sp))  

    if (i>0) {
      ans[i,] <- c(r.0, r.1, sn, sp, m.0, m.1, t.0, t.1)
    }
  }
  ans    
}
```

## **bespoke()**

```{r, eval=F}
bespoke <- function(n.0, n.1, mstr.0, mstr.1, 
                    a.sn, b.sn, a.sp, b.sp, 
                    N.REP=50000, N.BURN=100) {

  ### INPUTS
  ### n.j is size of control (j=0) and case (j=1) samples
  ### mstr.j is number (out of n.j) of apparently exposed
  ### a.sn, b.sn, a.sp, b.sp are hyperparameters
  
  ### LATENTS
  ### m.j is number (out of n.j) actually exposed
  ### t.j is number (out of mstr.j) actually exposed 
  ###     amongst the apparents

  ### OUTPUT output will be matrix, MC sample from posterior 
  ans <- matrix(NA, N.REP, 8)
  colnames(ans) <- c("r0","r1","sn","sp","m0","m1","t0","t1")
  ...
```


## Example

Say I am pretty sure that the exposure classification is very good (though probably not perfect).   I encode this with 
priors $Sn \sim \mbox{Beta}(140,10)$, $Sp \sim \mbox{Beta}(140,10)$.

*Sidenote:*    As a thought experiment, this would formally be the evidence had we done an external
validation of 150 truly unexposed and 150 truly exposed individuals, and found 10 misclassifications in each group.


```{r}
mc.opt <- bespoke(n.0=257+945, n.1=45+94, 
                  mstr.0=257, mstr.1=45, 
                  a.sn=140, b.sn=10, a.sp=140, b.sp=10)
```

## Example, continued

```{r}
### focus on target parameter
mc.trg <- logit(mc.opt[,"r1"]) - logit(mc.opt[,"r0"])
summary(mc.trg)

### estimate OR 
exp(mean(mc.trg))

### corresponding 95% credible interval
exp(quantile(mc.trg, c(0.025, 0.975)))
```

## Activity D - you try

Can you carry out a Bayesian analysis with *about* the same sort of uncertainty about misclassification parameters as
in Activity B.




## Activity D - further thinking/doing points

Depending on your background and interests, you could:

*  Look at the code for **bespoke()** to confirm how the MCMC algorithm (in this case the Gibbs sampler) bounces back and forth between sampling complete data given parameters, and sampling parameters given complete data.

*  Take a closer look at the Monte Carlo output to confirm that you do not get the luxury of *iid* draws from the posterior distribution, but rather have to live with serially autocorrelated draws.

*  Take a closer look at the Monte Carlo output to consider what the posterior distribution of $Sn$ and $Sp$ looks like, compared to the prior.

























